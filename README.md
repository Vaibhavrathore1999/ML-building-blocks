# ML-building-blocks üß†üîß

A collection of essential, from-scratch implementations and visualizations of core Machine Learning concepts using Python and Google Colab notebooks. This is a great starting point for learners who want to understand how things work under the hood.

---

## üìÅ Repository Structure

| Notebook | Description |
|----------|-------------|
| `Linear_Regression.ipynb` | Implementation and explanation of linear regression using least squares and gradient descent. |
| `Cross_Entropy.ipynb` | Intuitive derivation and implementation of cross-entropy loss (binary & categorical). |
| `Central_Limit_Theorem.ipynb` | Simulation-based demonstration of the Central Limit Theorem using dice and histograms. |
| `Attention.ipynb` | Explains self-attention and cross-attention mechanisms, with working examples. |
| `ViT_from_Scratch.ipynb` | Vision Transformer (ViT) implementation from scratch with image patching and self-attention. |

---

## üîç Motivation

Machine learning libraries often hide the math and mechanics. This repo helps you:
- Build **intuition** behind ML algorithms
- Write models from **scratch**
- Understand **loss functions**, **optimizers**, and **architectures**

---

## ‚úÖ Getting Started

You can run these notebooks directly in [Google Colab](https://colab.research.google.com):

```bash
# Clone the repository
git clone https://github.com/Vaibhavrathore1999/ML-building-blocks.git
